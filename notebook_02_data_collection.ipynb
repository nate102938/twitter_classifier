{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection methods\n",
    "- This notebook uses the Tweepy package to download tweets for specified accounts from the Twitter API. In order to use the API, you need your own bearer key, which serves as your authentication into the API.  If you are planning to use the API, put your bearer key into the variable 'bearer_key' in the constants section.\n",
    "- It uses a manually created account list file (accounts.csv) which has all of the Twitter handles to download tweets from, the class to assign to each handle, and how many tweets to get download from each handle.  \n",
    "- The accounts file is important to keep current in order to avoid downloading tweets from the same account multiple times as users of the Twitter API are limited to the number of tweets that can be pulled in a one month time period.  As such, when tweets for a particular handle are downloaded, the tweets are immediately appended to a tweets CSV file (tweet_list.csv) and the accounts file is updated to mark that handle as 'done'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary uncommon packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T17:30:35.296211Z",
     "start_time": "2023-02-22T17:30:33.224023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\nate\\anaconda3\\envs\\learn-env\\lib\\site-packages (4.12.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\users\\nate\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\nate\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\nate\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tweepy) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nate\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nate\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nate\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nate\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "# Tweet downloader\n",
    "! pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T17:30:35.888746Z",
     "start_time": "2023-02-22T17:30:35.311151Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import string\n",
    "import json\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T18:30:59.773980Z",
     "start_time": "2023-02-22T18:30:59.768203Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is the account list that we'll be pulling tweets from.  \n",
    "account_list_file = \"data/accounts.csv\"  \n",
    "\n",
    "# This is the file that we'll save tweet data to.\n",
    "tweet_list_file = 'data/tweet_list.csv'  \n",
    "\n",
    "# This is the file we save the twitter bearer key in.  Should be in folder included in gitignore b/c it's private info.\n",
    "twitter_key_file = \"private/twitter_key.json\"\n",
    "\n",
    "# Gets the twitter key from the private folder (not uploaded to github, included in gitignore)\n",
    "def get_twitter_key():\n",
    "    with open(twitter_key_file) as f:\n",
    "        data = json.load(f)\n",
    "    return data['bearer_key']\n",
    "\n",
    "# This the key needed to download from the API.  Get this from twitter key file.\n",
    "bearer_key = get_twitter_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T03:18:18.831288Z",
     "start_time": "2023-02-15T03:18:18.341363Z"
    }
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account list management functions\n",
    "\n",
    "These functions manage the list of accounts to pull tweets from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T18:31:05.962700Z",
     "start_time": "2023-02-22T18:31:05.952280Z"
    }
   },
   "outputs": [],
   "source": [
    "# This downloads the account list file (the file that has the accounts we'll pull tweets from)\n",
    "def get_account_list_from_file():\n",
    "    \n",
    "    # Get list of accounts from CSV file\n",
    "    df_accounts = pd.read_csv(account_list_file)\n",
    "\n",
    "    # Create a dataframe from the file contents\n",
    "    df_accounts.columns = [n.strip() for n in df_accounts.columns]\n",
    "    df_accounts['Count_Plan'] = df_accounts['Count_Plan'].astype(int)\n",
    "    df_accounts['Count_Actual'] = df_accounts['Count_Actual'].astype(int)\n",
    "    df_accounts['Done'] = df_accounts['Done'].astype(bool)\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return df_accounts\n",
    "\n",
    "# This function saves the account list.  It's saved after each handle download.  \n",
    "def save_account_list_to_file():\n",
    "    account_list.to_csv(account_list_file, index=False)\n",
    "    \n",
    "# This is to reset the account list file.  Should rarely be used unless we want to restart the downloads.\n",
    "def reset_account_list_done():\n",
    "    account_list['Done'] = False\n",
    "    account_list['Count_Actual'] = 0\n",
    "    save_account_list_to_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:19:51.114581Z",
     "start_time": "2023-02-15T04:19:51.102208Z"
    }
   },
   "source": [
    "### Tweet downloading and saving functions\n",
    "\n",
    "These functions perform the actual downloading and saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T18:31:07.014386Z",
     "start_time": "2023-02-22T18:31:06.993837Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to request tweets from the twitter API for a specified handle, specified number of tweets, and add the specified class to it\n",
    "# Return the list of tweets\n",
    "\n",
    "def get_tweets(username, class_, number_of_tweets):\n",
    "    # This is the key to use to download the tweets\n",
    "   \n",
    "    client = tweepy.Client(bearer_token=bearer_key)\n",
    "    user_id = client.get_user(username=username).data.id\n",
    "\n",
    "    # Uses the paginator to request as many tweets as we want (paginator makes it possible to download more than 100 at a time\n",
    "    tweets = []\n",
    "    for tweet in tweepy.Paginator(client.get_users_tweets, user_id, tweet_fields=['created_at', 'author_id'],expansions=[''], max_results=100, exclude=['replies']).flatten(limit=number_of_tweets):\n",
    "        # Scrub the text of any non-readable characters\n",
    "        text = \"\".join(i for i in tweet.text if i in string.printable)\n",
    "        # Scrub the text of any newlines\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        # Put the tweet info into a new dictionary\n",
    "        tweets.append({\n",
    "            \"user_name\"  : str(username),\n",
    "            'class'      : str(class_),\n",
    "            \"id\"         : str(tweet.id),\n",
    "            \"text\"       : str(text),\n",
    "            \"author_id\"  : str(tweet.author_id),\n",
    "            \"created_at\" : str(tweet.created_at)\n",
    "        })\n",
    "    return tweets\n",
    "\n",
    "# Function to append newly downloaded tweets to file\n",
    "def append_to_tweet_file(tweets):\n",
    "    field_names = ['user_name','class','id','text','author_id', 'created_at']\n",
    "    \n",
    "    # if the tweet data file doesn't exist, we're starting from scratch.  Make the file and put the headers at the top. \n",
    "    if not os.path.exists(tweet_list_file):\n",
    "        with open(tweet_list_file, 'a') as csv_file:\n",
    "            writer = csv.writer(csv_file, quoting=csv.QUOTE_NONNUMERIC) \n",
    "            writer.writerow(field_names)\n",
    "            \n",
    "    # Append the new data to file\n",
    "    with open(tweet_list_file, 'a') as csv_file:\n",
    "        writer = csv.writer(csv_file, quoting=csv.QUOTE_NONNUMERIC) \n",
    "        for t in tweets:\n",
    "            writer.writerow([t['user_name'], t['class'], t['id'], t['text'], t['author_id'], t['created_at']])\n",
    "\n",
    "# Function to pull the next handle from the accounts file and \n",
    "def get_next_handle():\n",
    "    # Find first handle with a False in 'Done' \n",
    "    next_account = 0\n",
    "    total_accounts = len(account_list)\n",
    "    count = 0\n",
    "    \n",
    "    # Loop through the account list to find the next one that doesn't say 'Done'.  This is the next handle to download.  \n",
    "    for n in range(0, total_accounts):\n",
    "        if account_list.loc[n, 'Done'] == False:\n",
    "            # Found next handle to download.  Break the loop.\n",
    "            next_account = n\n",
    "            break\n",
    "\n",
    "    \n",
    "    # Double check we found a handle that doesn't say Done, and then get the tweets for that handle\n",
    "    if account_list.loc[next_account, 'Done'] == False:\n",
    "        handle_to_get = account_list.loc[next_account,'Twitter handle']\n",
    "        class_assignment = account_list.loc[next_account,'Class']\n",
    "        number_to_get = account_list.loc[next_account,'Count_Plan']\n",
    "        # Print what we are downloading\n",
    "        print(f\"Requesting {next_account+1}/{total_accounts-1}: {handle_to_get}, {class_assignment}, {number_to_get} tweets.  \", end=\"\")\n",
    "\n",
    "        tweetlist = get_tweets(handle_to_get, class_assignment, number_to_get)\n",
    "        count = len(tweetlist)\n",
    "        if count > 0:\n",
    "            # We've got tweets.  Mark it done in the accounts file and save it. \n",
    "            print(f\"  Received: {count} tweets.\")\n",
    "            append_to_tweet_file(tweetlist)\n",
    "            account_list.loc[next_account, \"Done\"] = True\n",
    "            account_list.loc[next_account, \"Count_Actual\"] = count\n",
    "            save_account_list_to_file()\n",
    "\n",
    "    return count  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pulling of tweets to make sure it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T18:31:10.516654Z",
     "start_time": "2023-02-22T18:31:09.580801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_name': 'tombrady',\n",
       "  'class': 'test',\n",
       "  'id': '1626668046931697664',\n",
       "  'text': 'Looks like appropriate parade behavior to me  @PatrickMahomes https://t.co/T69dLoWxmS',\n",
       "  'author_id': '1108050829393707008',\n",
       "  'created_at': '2023-02-17 19:40:59+00:00'},\n",
       " {'user_name': 'tombrady',\n",
       "  'class': 'test',\n",
       "  'id': '1626265734614589445',\n",
       "  'text': 'Hey @Autograph family, were one month away from my unofficial retirement party in Tampa on March 16th. Cant wait to celebrate with everyone from The Huddle.   You down @RobGronkowski? Going over the list now and think I can get you in',\n",
       "  'author_id': '1108050829393707008',\n",
       "  'created_at': '2023-02-16 17:02:20+00:00'},\n",
       " {'user_name': 'tombrady',\n",
       "  'class': 'test',\n",
       "  'id': '1624910619559227392',\n",
       "  'text': 'Two of the best tonight in Pat and Jalen. Good luck to KC and Philly, cant wait to watch.',\n",
       "  'author_id': '1108050829393707008',\n",
       "  'created_at': '2023-02-12 23:17:35+00:00'},\n",
       " {'user_name': 'tombrady',\n",
       "  'class': 'test',\n",
       "  'id': '1624908559736602624',\n",
       "  'text': 'https://t.co/iVi1K6y2pd',\n",
       "  'author_id': '1108050829393707008',\n",
       "  'created_at': '2023-02-12 23:09:24+00:00'},\n",
       " {'user_name': 'tombrady',\n",
       "  'class': 'test',\n",
       "  'id': '1623349939941314561',\n",
       "  'text': 'Thanks for joining Peyton! Full episode: https://t.co/RAhxnypx8m https://t.co/Mv4WBGxcWH',\n",
       "  'author_id': '1108050829393707008',\n",
       "  'created_at': '2023-02-08 15:56:00+00:00'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tweets(\"tombrady\", \"test\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download tweets\n",
    "\n",
    "Two download methods are provided below.  One to download one handle's tweets (the next handle in the account list that isn't downloaded yet).  One to download a batch of the next 50 handles in the account list.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the next handle's tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T18:31:13.955996Z",
     "start_time": "2023-02-22T18:31:13.936950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get account list from file\n",
    "account_list = get_account_list_from_file()\n",
    "\n",
    "# Download and save the next handle\n",
    "count = get_next_handle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the next 50 handles' tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T05:12:03.784521Z",
     "start_time": "2023-02-15T05:12:03.762597Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through the next 50 handles to pull from the account file\n",
    "for n in range(50):\n",
    "    count = get_next_handle()  # Returns the number of tweets downloaded.  If zero, end, something didn't work.  \n",
    "    if count == 0:\n",
    "        break\n",
    "    # Sleep for 1 second and then move on to the next handle.  Give it time to download.\n",
    "    sleep(1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data review\n",
    "\n",
    "Review downloaded data and the account status file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review tweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load downloaded tweets from file (assumes the tweet file already has downloaded tweets in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T18:31:28.385650Z",
     "start_time": "2023-02-22T18:31:27.932217Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BennieGThompson</td>\n",
       "      <td>Politics - Liberal</td>\n",
       "      <td>1.620580e+18</td>\n",
       "      <td>Today marks the 83rd anniversary of the first ...</td>\n",
       "      <td>82453460.0</td>\n",
       "      <td>2023-02-01 00:45:11+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BennieGThompson</td>\n",
       "      <td>Politics - Liberal</td>\n",
       "      <td>1.620120e+18</td>\n",
       "      <td>RT @VP: President Biden and I are just getting...</td>\n",
       "      <td>82453460.0</td>\n",
       "      <td>2023-01-30 17:46:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BennieGThompson</td>\n",
       "      <td>Politics - Liberal</td>\n",
       "      <td>1.620120e+18</td>\n",
       "      <td>RT @RepJeffries: We will never negotiate away ...</td>\n",
       "      <td>82453460.0</td>\n",
       "      <td>2023-01-30 17:46:12+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BennieGThompson</td>\n",
       "      <td>Politics - Liberal</td>\n",
       "      <td>1.620120e+18</td>\n",
       "      <td>https://t.co/Ze7ePCUJJ2</td>\n",
       "      <td>82453460.0</td>\n",
       "      <td>2023-01-30 17:45:55+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BennieGThompson</td>\n",
       "      <td>Politics - Liberal</td>\n",
       "      <td>1.620060e+18</td>\n",
       "      <td>https://t.co/ley5hNsz0y https://t.co/RFdTeGXGO1</td>\n",
       "      <td>82453460.0</td>\n",
       "      <td>2023-01-30 14:10:33+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136667</th>\n",
       "      <td>LinusTech</td>\n",
       "      <td>Science / Technology</td>\n",
       "      <td>1.550000e+18</td>\n",
       "      <td>NEW VIDEO!: who would PAY for this Weird Fan? ...</td>\n",
       "      <td>403614288.0</td>\n",
       "      <td>2022-08-02 17:18:49+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136668</th>\n",
       "      <td>LinusTech</td>\n",
       "      <td>Science / Technology</td>\n",
       "      <td>1.550000e+18</td>\n",
       "      <td>Big shoutout to @LongMcQuade for providing us ...</td>\n",
       "      <td>403614288.0</td>\n",
       "      <td>2022-08-02 17:13:55+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136669</th>\n",
       "      <td>LinusTech</td>\n",
       "      <td>Science / Technology</td>\n",
       "      <td>1.550000e+18</td>\n",
       "      <td>New Video!!: Should I take back my $225,000?  ...</td>\n",
       "      <td>403614288.0</td>\n",
       "      <td>2022-08-01 18:45:12+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136670</th>\n",
       "      <td>LinusTech</td>\n",
       "      <td>Science / Technology</td>\n",
       "      <td>1.550000e+18</td>\n",
       "      <td>we finally got colton a standing desk https://...</td>\n",
       "      <td>403614288.0</td>\n",
       "      <td>2022-08-01 16:02:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136671</th>\n",
       "      <td>LinusTech</td>\n",
       "      <td>Science / Technology</td>\n",
       "      <td>1.550000e+18</td>\n",
       "      <td>upcoming DLC for GTA 6 https://t.co/jluyfFA5f9</td>\n",
       "      <td>403614288.0</td>\n",
       "      <td>2022-08-01 00:00:26+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136672 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_name                 class            id  \\\n",
       "0       BennieGThompson    Politics - Liberal  1.620580e+18   \n",
       "1       BennieGThompson    Politics - Liberal  1.620120e+18   \n",
       "2       BennieGThompson    Politics - Liberal  1.620120e+18   \n",
       "3       BennieGThompson    Politics - Liberal  1.620120e+18   \n",
       "4       BennieGThompson    Politics - Liberal  1.620060e+18   \n",
       "...                 ...                   ...           ...   \n",
       "136667        LinusTech  Science / Technology  1.550000e+18   \n",
       "136668        LinusTech  Science / Technology  1.550000e+18   \n",
       "136669        LinusTech  Science / Technology  1.550000e+18   \n",
       "136670        LinusTech  Science / Technology  1.550000e+18   \n",
       "136671        LinusTech  Science / Technology  1.550000e+18   \n",
       "\n",
       "                                                     text    author_id  \\\n",
       "0       Today marks the 83rd anniversary of the first ...   82453460.0   \n",
       "1       RT @VP: President Biden and I are just getting...   82453460.0   \n",
       "2       RT @RepJeffries: We will never negotiate away ...   82453460.0   \n",
       "3                                 https://t.co/Ze7ePCUJJ2   82453460.0   \n",
       "4         https://t.co/ley5hNsz0y https://t.co/RFdTeGXGO1   82453460.0   \n",
       "...                                                   ...          ...   \n",
       "136667  NEW VIDEO!: who would PAY for this Weird Fan? ...  403614288.0   \n",
       "136668  Big shoutout to @LongMcQuade for providing us ...  403614288.0   \n",
       "136669  New Video!!: Should I take back my $225,000?  ...  403614288.0   \n",
       "136670  we finally got colton a standing desk https://...  403614288.0   \n",
       "136671     upcoming DLC for GTA 6 https://t.co/jluyfFA5f9  403614288.0   \n",
       "\n",
       "                       created_at  \n",
       "0       2023-02-01 00:45:11+00:00  \n",
       "1       2023-01-30 17:46:29+00:00  \n",
       "2       2023-01-30 17:46:12+00:00  \n",
       "3       2023-01-30 17:45:55+00:00  \n",
       "4       2023-01-30 14:10:33+00:00  \n",
       "...                           ...  \n",
       "136667  2022-08-02 17:18:49+00:00  \n",
       "136668  2022-08-02 17:13:55+00:00  \n",
       "136669  2022-08-01 18:45:12+00:00  \n",
       "136670  2022-08-01 16:02:07+00:00  \n",
       "136671  2022-08-01 00:00:26+00:00  \n",
       "\n",
       "[136672 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_list_df = pd.read_csv(tweet_list_file)\n",
    "tweet_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T18:31:37.004644Z",
     "start_time": "2023-02-22T18:31:36.971159Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WSJbusiness        1606\n",
       "LinusTech           850\n",
       "techreview          850\n",
       "ScienceMagazine     850\n",
       "NatGeo              850\n",
       "                   ... \n",
       "repvalhoyle          10\n",
       "JMoylanforGuam       10\n",
       "NBCNetwork            7\n",
       "RepJeffJackson        2\n",
       "DNC                   1\n",
       "Name: user_name, Length: 612, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_list_df.user_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we've successfully successfully downloaded from all accounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Tweets totaled ~136K in count from 612 accounts.  \n",
    "\n",
    "Now I'll move on to modeling.  Proceed back to the main notebook. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
